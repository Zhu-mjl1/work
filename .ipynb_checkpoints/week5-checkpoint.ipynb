{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3876424a",
   "metadata": {},
   "source": [
    "# Week5\n",
    "*time: 2024.05.06 - 2024.05.12*\n",
    "## 3. 应用机器学习的建议\n",
    "### 3.1 模型评估\n",
    "* 训练集和测试集：训练集用于训练模型的参数，测试集用于评估模型的性能\n",
    "* 回归：使用平方误差（不包含正则化项）评估模型的性能\n",
    "    * 测试误差：是测试集上的平均误差\n",
    "    * 训练误差：训练集上的平均误差\n",
    "* 分类：使用分类错误率来评估模型的性能\n",
    "    * 测试错误率：测试集上被错误分类的样本的比例\n",
    "    * 训练错误率：训练集上被错误分类的样本的比例\n",
    "* 通过计算测试误差和训练误差，可以了解模型在测试集和训练集上的表现，从而判断模型的泛化能力\n",
    "### 3.2 模型选择和训练/交叉验证/测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c96b13f",
   "metadata": {},
   "source": [
    "* 为了评估模型的性能，通常将数据分为三个部分：训练集、交叉验证集和测试集。\n",
    "* 训练集用于训练模型，即通过训练数据来调整模型的参数，使其能够更好地拟合数据。\n",
    "* 交叉验证集用于选择最佳的模型。具体地，可以尝试不同的模型或不同的超参数设置，并使用交叉验证集来评估它们的性能。\n",
    "* 测试集用于最终评估模型的性能。测试集是模型从未见过的数据，因此可以用来估计模型在真实世界中的表现。\n",
    "* 不能使用测试集进行模型选择的原因：泄露信息，导致过分乐观地估计模型的性能。\n",
    "\n",
    "```python\n",
    "# 获取60%的数据集作为训练集。将剩余的40%放在临时变量中,x_和y_\n",
    "x_train, x_, y_train, y_= train_test_split(x, y, test_size = 0.40, random_state = 1)\n",
    "# 分离其中的40%，其中一半是cross validation,另一半作为test set.\n",
    "x_cv, x_test, y_cv, y_test = train_test_split(x_, y_, test_size = 0.50, random_state = 1)\n",
    "# 初始化类\n",
    "scaler_linear = StandardScaler()\n",
    "# 计算训练集的均值和标准差，然后转换它\n",
    "X_train_scaled = scaler_linear.fit_transform(x_train)\n",
    "# 初始化类\n",
    "linear_model = LinearRegression()\n",
    "# 训练模型\n",
    "linear_model.fit(X_train_scaled, y_train )\n",
    "#传入X_train并获得预测\n",
    "yhat = linear_model.predict(X_train_scaled)\n",
    "#使用scikit-learn的函数并除以2\n",
    "print(f\"training MSE (using sklearn function): {mean_squared_error(y_train, yhat) / 2}\")\n",
    "\n",
    "total_squared_error = 0\n",
    "\n",
    "for i in range(len(yhat)):\n",
    "    squared_error_i  = (yhat[i] - y_train[i])**2\n",
    "    total_squared_error += squared_error_i                                              \n",
    "\n",
    "mse = total_squared_error / (2*len(yhat))\n",
    "\n",
    "X_cv_scaled = scaler_linear.transform(x_cv)\n",
    "yhat = linear_model.predict(X_cv_scaled)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f4a89f",
   "metadata": {},
   "source": [
    "### 3.3 偏差和方差(bias and variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a669ad9",
   "metadata": {},
   "source": [
    "* underfit: high bais\n",
    "* ovewrfit: high variance\n",
    "* 偏差（bias）指的是算法对训练集的拟合程度。如果算法的偏差很高，意味着它无法很好地拟合训练集，即欠拟合。\n",
    "* 方差（variance）指的是算法对新数据的泛化能力。如果算法的方差很高，意味着它在训练集上表现很好，但在新数据上表现较差，即过拟合。\n",
    "\n",
    "* 高偏差问题：如果算法在训练集上表现不佳（J_train高），则可能存在高偏差问题。\n",
    "* 高方差问题：如果算法在交叉验证集上的误差远大于训练集上的误差（J_cv >> J_train），则可能存在高方差问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87671d17",
   "metadata": {},
   "source": [
    "### 3.4 benchmark/ baseline level performance\n",
    "* 在判断学习算法是否存在高偏差或高方差问题时，可以通过比较训练误差和交叉验证误差与基准水平的差异来判断\n",
    "* 基准水平可以是人类在该任务上的表现，也可以是其他算法的性能\n",
    "* 如果训练误差远高于基准水平，而交叉验证误差与训练误差相差不大，那么算法可能欠拟合问题\n",
    "* 如果训练误差与基准水平相差不大，但交叉验证误差远高于训练误差，那么算法可能存在过拟合问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da60e9b",
   "metadata": {},
   "source": [
    "### 3.5 学习曲线\n",
    "\n",
    "* 学习算法面临高偏差时，增加训练数据可能不会有太大帮助\n",
    "* 学习算法面临高方差时，增加训练数据可能会有很大帮助\n",
    "* 学习曲线可以帮助我们判断算法是面临高偏差还是高方差的问题\n",
    "* 当学习曲线显示出训练误差和交叉验证误差都很高时，可能是高偏差(under fitting)的问题\n",
    "* 当学习曲线显示出训练误差很低，但交叉验证误差很高时，可能是高方差(over fitting)的问题\n",
    "* 绘制学习曲线需要训练多个模型，使用不同大小的训练集，并计算训练误差和交叉验证误差"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6633fe7c",
   "metadata": {},
   "source": [
    "###  3.6 改进算法性能\n",
    "* **如果算法存在高偏差问题**（即在训练集上表现不佳或欠拟合)，可以尝试以下方法：\n",
    "    * 增加训练样本数量\n",
    "    * 减少特征数量或简化模型\n",
    "    * 减小正则化参数$\\lambda$的值\n",
    "    \n",
    "* **如果算法存在高方差问题**（即在训练集上表现良好但在交叉验证集上表现不佳，或过拟合），可以尝试以下方法：\n",
    "    * 增加训练样本数量\n",
    "    * 增加特征数量或复杂化模型\n",
    "    * 增大正则化参数$\\lambda$的值\n",
    "\n",
    "* 加入正则化的训练模型:\n",
    "```python\n",
    "tf.random.set_seed(1234)\n",
    "model_r = Sequential(\n",
    "    [\n",
    "        Dense(120, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(0.1), name=\"L1\"), \n",
    "        Dense(40, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(0.1), name=\"L2\"),  \n",
    "        Dense(classes, activation = 'linear', name=\"L3\")  \n",
    "    ], name=\"ComplexRegularized\"\n",
    ")\n",
    "model_r.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "    optimizer=tf.keras.optimizers.Adam(0.01),                             \n",
    ")\n",
    "\n",
    "model_r.fit(\n",
    "    X_train,y_train,\n",
    "    epochs=1000\n",
    ")                                   \n",
    "```\n",
    "\n",
    "* 可以通过迭代尝试一系列的$\\lambda$值试图找到最合适的正则化参数:\n",
    "\n",
    "```python\n",
    "tf.random.set_seed(1234)\n",
    "lambdas = [0.0, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3]\n",
    "models=[None] * len(lambdas)\n",
    "\n",
    "for i in range(len(lambdas)):\n",
    "    lambda_ = lambdas[i]\n",
    "    models[i] =  Sequential(\n",
    "        [\n",
    "            Dense(120, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(lambda_)),\n",
    "            Dense(40, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(lambda_)),\n",
    "            Dense(classes, activation = 'linear')\n",
    "        ]\n",
    "    )\n",
    "    models[i].compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "    )\n",
    "\n",
    "    models[i].fit(\n",
    "        X_train,y_train,\n",
    "        epochs=1000\n",
    "    )\n",
    "    print(f\"Finished lambda = {lambda_}\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc286a8",
   "metadata": {},
   "source": [
    "### 3.7 偏差、方差和神经网络\n",
    "* 高偏差：使用更大的神经网络，增加隐藏层的数量或每层的隐藏单元数量\n",
    "* 高方差：获取更多的数据，以提供更多的样本来训练模型\n",
    "* 只要正则化得当，更大（更复杂）的神经网络一般不会导致更严重的过拟合问题，但对算力提出了更高的要求，并且训练的过程可能会更慢\n",
    "* 实际应用时高方差问题较高偏差更严重\n",
    "* 增加神经网络的大小和获取更多的数据都有一定的限制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70292dc1",
   "metadata": {},
   "source": [
    "\n",
    "### 3.8 迁移学习\n",
    "* 迁移学习是一种利用从不同任务中获得的数据来帮助解决当前任务的技术。\n",
    "* 在迁移学习中，你可以使用一个已经在大型数据集上训练好的神经网络作为起点，然后通过微调参数来适应当前任务\n",
    "* 迁移学习的关键是将已经训练好的神经网络的参数复制到新的神经网络中，并根据需要调整输出层的参数\n",
    "* 可以选择只训练输出层的参数，或者训练整个网络的参数，但前四层的参数将使用从上面训练得到的值进行初始化\n",
    "* 依赖于预训练和微调步骤之间的数据类型的一致性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5c0009",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
