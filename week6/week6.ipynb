{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8723a359",
   "metadata": {},
   "source": [
    "# week6\n",
    "*from 2024-05-13 to 2024-05-19* \n",
    "## S2_W4_决策树_2\n",
    "### 4.6 tree ensembles\n",
    "- 使用单一决策树的缺点：\n",
    "  - 对数据的微小变化非常敏感\n",
    "  - 可能导致根节点的分裂特征和整棵树结构的变化\n",
    "\n",
    "- 解决方案：树集成\n",
    "  - 构建多棵决策树，而不是单一决策树\n",
    "  - 让多个决策树投票，以获得更稳健的预测结果\n",
    "  - 通过投票减少对单一决策树的依赖，提高算法的稳健性\n",
    "\n",
    "- 示例：\n",
    "  - 仅改变一个训练样本会导致决策树选择不同的特征进行分裂，生成完全不同的树\n",
    "  - 多棵树对同一个测试样本进行投票，最终预测结果是多数决\n",
    "\n",
    "- 树集成的关键技术：\n",
    "  - 有放回抽样（将在后续视频中详细讲解）\n",
    "  - 帮助生成多个不同但合理的决策树，构建稳健的树集成模型\n",
    "\n",
    "### 4.7 随机森林算法\n",
    "\n",
    "* **Given training set of size m** \n",
    "\n",
    "For $b$ = 1 to $B$:\n",
    "\n",
    "    Use sampling with replacement to create a new training set of size m \n",
    "    \n",
    "    Train a decision tree on the new dataset\n",
    "\n",
    "* **randomizing the feature choice**\n",
    "\n",
    "    * At each node, when choosing a teature to use to split, if n features are avaliable, pick a random subset of k<n(commonly choose k = sqrt(n)) features and allow the algorithm to only choose from that subset of features.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2e4ead",
   "metadata": {},
   "source": [
    "### 4.8 XGBoost\n",
    "\n",
    "**算法原理：**\n",
    "\n",
    "    1.初始化模型：初始化一个XGBoost模型（决策树的集合）\n",
    "\n",
    "    2.迭代训练：进行多次迭代训练，每次迭代中都会根据之前训练的树的表现情况来调整训练样本的权重\n",
    "\n",
    "    3.对于被之前的树错误分类的样本，将在下一次迭代中增加其权重，因此更关注被错误分类的样本（所在的子集）。\n",
    "\n",
    "    4.构建决策树：在每次迭代中，使用调整后的样本权重来构建一个新的决策树\n",
    "\n",
    "    5.训练完毕后得到集成模型\n",
    "\n",
    "    6.预测\n",
    "**Using XGBoost:**\n",
    "```python\n",
    "#-----------Classification--------------\n",
    "from xgboost import XGBClassifier\n",
    "    \n",
    "model = XGBClassifier()\n",
    "    \n",
    "model.fit (X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "#-------------Regression----------------\n",
    "from xgboost import XGBRegressor\n",
    "    \n",
    "model = XGBRegressor()\n",
    "    \n",
    "model.fit (X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c62384",
   "metadata": {},
   "source": [
    "### 4.9  比较决策树和神经网络\n",
    "决策树：\n",
    "\n",
    "    决策树是一种基于树状结构的学习算法\n",
    "    它适用于处理结构化数据，例如电子表格中的数据\n",
    "    决策树可以用于分类问题（预测离散类别）和回归问题（预测连续数值）\n",
    "    决策树训练速度快，并且小型决策树易于解释\n",
    "    \n",
    "神经网络：\n",
    "\n",
    "    神经网络是一种模拟人脑神经元工作方式的学习算法\n",
    "    它适用于处理各种类型的数据，包括结构化数据和非结构化数据（如图像、音频和文本）\n",
    "    神经网络在处理非结构化数据方面表现出色\n",
    "    神经网络训练速度可能较慢，但可以通过使用预训练和迁移学习来提高性能\n",
    "    在构建多个机器学习模型的系统时，神经网络可能更容易组合和训练\n",
    "    \n",
    "需要的库：\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e824422",
   "metadata": {},
   "source": [
    "### **eg.heart disease:**\n",
    "#### Attribute Information\n",
    "- 年龄：患者的年龄[年]\n",
    "\n",
    "- 性别：患者的性别[M：男性，F：女性]\n",
    "\n",
    "- 胸痛类型：胸痛类型[TA：典型心绞痛，ATA：非典型心绞痛，NAP：非心绞痛，ASY：无症状]\n",
    "\n",
    "- RestingBP：静息血压[mm Hg]\n",
    "\n",
    "- 胆固醇：血清胆固醇[mm/dl]\n",
    "\n",
    "- FastingBS：空腹血糖[1：如果FastingBS> 120 mg/dl，0：否则]\n",
    "\n",
    "- 静息心电图：静息心电图结果[正常：正常，ST：有ST-T波异常（T波反转和/或ST升高或下降>0.05 mV），LVH：根据Estes的标准显示可能或确定的左心室肥厚]\n",
    "\n",
    "- MaxHR：达到最大心率[数值在60到202之间]\n",
    "\n",
    "- 运动心绞痛：运动诱发的心绞痛[Y：是，N：否]\n",
    "\n",
    "- Oldpeak：oldpeak = ST [在抑郁症中测量的数值]\n",
    "\n",
    "- ST_Slope：峰值练习ST段的斜率[向上：向上倾斜，平坦：平坦，向下：向下倾斜]\n",
    "\n",
    "- 心脏疾病：输出类[1：心脏病，0：正常]\n",
    "```python\n",
    "# Load the dataset using pandas\n",
    "df = pd.read_csv(\"heart.csv\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83edc01c",
   "metadata": {},
   "source": [
    "#### One-hot encoding using Pandas\n",
    "```python\n",
    "#删除二元变量\n",
    "cat_variables = ['Sex',\n",
    "'ChestPainType',\n",
    "'RestingECG',\n",
    "'ExerciseAngina',\n",
    "'ST_Slope'\n",
    "]\n",
    "\n",
    "\n",
    "```\n",
    "`pd.get_dummies`\n",
    "\n",
    "- 数据：要使用的$DataFrame$\n",
    "\n",
    "- 前缀：带有前缀的列表，以便我们知道我们正在处理哪个值\n",
    "\n",
    "- 列：将进行一次性编码的列列表。“前缀”和“列”必须具有相同的长度。\n",
    "```python\n",
    "# 这将用单热编码的列替换原有的列\n",
    "df = pd.get_dummies(data = df,\n",
    "                         prefix = cat_variables,\n",
    "                         columns = cat_variables)\n",
    "features = [x for x in df.columns if x not in 'HeartDisease'] ## Removing our target variable\n",
    "```\n",
    "#### Splitting the Dataset\n",
    "```python\n",
    "\n",
    "help(train_test_split)\n",
    "X_train, X_val, y_train, y_val = train_test_split(df[features], df['HeartDisease'], train_size = 0.8, random_state = RANDOM_STATE)\n",
    "\n",
    "# keep the shuffle = True \n",
    "\n",
    "\n",
    "```\n",
    "hyperparameters will use and investigate:\n",
    "\n",
    " - min_samples_split: The minimum number of samples required to split an internal node. \n",
    "   - Choosing a higher min_samples_split can reduce the number of splits and may help to reduce overfitting.\n",
    " - max_depth: The maximum depth of the tree. \n",
    "   - Choosing a lower max_depth can reduce the number of splits and may help to reduce overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68245f7a",
   "metadata": {},
   "source": [
    "## S3_W1_无监督算法\n",
    "\n",
    "### 1.1$ K-means$算法\n",
    "\n",
    "$K-means$算法是一种聚类算法，其主要目的是将数据点分成不同的簇\n",
    "\n",
    "- **算法步骤：**\n",
    "    - 1. 随机选择K个点作为初始质心。\n",
    "    - 2. 将每个点分配到最近的质心所属的簇。\n",
    "    - 3. 对每个簇，计算该簇中所有数据点的平均值，以此作为新的质心位置并更新。\n",
    "    - 4. 重复步骤2和步骤3，直到质心的位置不再发生变化或达到预设的迭代次数为止。\n",
    "\n",
    "\n",
    "- **核心目标：**\n",
    "    - 最小化数据点与其所属簇质心之间的平方距离之和，也被称为簇内平方和$SSE$\n",
    "\n",
    "- $K-means$算法对于初始质心的选择非常敏感，不同的初始质心可能会导致不同的聚类结果\n",
    "- 因此通常多次执行，选择$SSE$最小的聚类结果作为最终结果\n",
    "\n",
    "### 1.2 $K-means$算法使用的成本函数\n",
    "\n",
    "- $K-means$算法的成本函数也被称为畸变函数（distortion function）。\n",
    "- 用于衡量每个数据点与其所属聚类中心之间的平方距离的平均值。\n",
    "- 具体而言，$K-means$算法的成本函数$J$定义如下：\n",
    "$$\n",
    "J = \\frac{1}{m}  \\sum_{i=1} ^{m} ||X_i - \\mu _{C_i}||^2\n",
    "$$\n",
    "其中，$J$表示成本函数，$M$表示数据点的总数，$X_i$表示第$i$个数据点，$\\mu_{C_i}$表示第$i$个数据点所属聚类中心的位置。\n",
    "- 最小化$J$的方法即$1.1$中所述\n",
    "\n",
    "### 1.3 异常检测算法\n",
    "* 为了评估算法的性能，我们可以使用以下指标：\n",
    "\n",
    "* 准确率（Accuracy）：准确率是指算法正确识别出的异常样本和正常样本的比例。它可以通过计算以下公式得到：\n",
    "$$准确率 =\\frac{ 真阳性 + 真阴性} {真阳性 + 假阳性 + 真阴性 + 假阴性}$$准确率越高，表示算法的性能越好。\n",
    "\n",
    "* 召回率（Recall）：召回率是指算法正确识别出的异常样本占所有实际异常样本的比例。它可以通过计算以下公式得到：\n",
    "$$召回率 =\\frac{ 真阳性 }{ 真阳性 + 假阴性}$$ 召回率越高，表示算法能够更好地找出异常样本。\n",
    "\n",
    "* F1分数（F1 Score）：F1分数是准确率和召回率的综合指标，它综合考虑了算法的精确性和召回率。\n",
    "     $$ F1分数 = 2 * \\frac{准确率 * 召回率} {准确率 + 召回率 }$$\n",
    "    * F1分数越高，表示算法在准确性和召回率方面的平衡性更好。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7487b85e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
