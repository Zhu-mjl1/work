{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9087ede",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T14:52:21.584523Z",
     "start_time": "2024-06-28T14:52:21.560073Z"
    }
   },
   "source": [
    "# 深度学习 C3_W2\n",
    "\n",
    "### 1. 错误分析\n",
    "\n",
    "- **错误分析**：\n",
    "  - 错误分析是指对模型的预测错误进行系统性的检查和分析，以找出导致错误的原因，从而改进模型的性能。\n",
    "  - **步骤**：\n",
    "    1. 收集模型的错误预测。\n",
    "    2. 分类错误类型（例如，数据噪声、模型欠拟合、模型过拟合等）。\n",
    "    3. 分析每种错误类型的频率和分布。\n",
    "    4. 识别和修复导致错误的主要因素。\n",
    "\n",
    "#### 代码示例\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 假设我们有预测结果和真实标签\n",
    "y_true = np.array([1, 0, 1, 1, 0, 1, 0, 0, 1, 0])\n",
    "y_pred = np.array([1, 0, 0, 1, 0, 1, 0, 1, 1, 0])\n",
    "\n",
    "# 计算错误类型\n",
    "errors = y_true != y_pred\n",
    "error_indices = np.where(errors)[0]\n",
    "\n",
    "# 显示错误分析结果\n",
    "error_analysis = pd.DataFrame({\n",
    "    'Index': error_indices,\n",
    "    'True Label': y_true[error_indices],\n",
    "    'Predicted Label': y_pred[error_indices]\n",
    "})\n",
    "\n",
    "print(error_analysis)\n",
    "```\n",
    "\n",
    "### 2. 多任务学习\n",
    "\n",
    "- **多任务学习（Multi-task Learning）**：\n",
    "  - 多任务学习是指同时训练模型来完成多个相关任务，以期通过共享表示来提高模型的泛化能力。\n",
    "  - **优点**：\n",
    "    - 共享表示可以减少模型的过拟合。\n",
    "    - 相关任务的联合训练可以提高模型的泛化能力。\n",
    "\n",
    "#### 代码示例\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 定义输入\n",
    "input_layer = Input(shape=(784,))\n",
    "\n",
    "# 共享层\n",
    "shared_layer = Dense(64, activation='relu')(input_layer)\n",
    "\n",
    "# 任务1输出\n",
    "task1_output = Dense(10, activation='softmax', name='task1_output')(shared_layer)\n",
    "\n",
    "# 任务2输出\n",
    "task2_output = Dense(1, activation='sigmoid', name='task2_output')(shared_layer)\n",
    "\n",
    "# 构建模型\n",
    "model = Model(inputs=input_layer, outputs=[task1_output, task2_output])\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', \n",
    "              loss={'task1_output': 'sparse_categorical_crossentropy', 'task2_output': 'binary_crossentropy'},\n",
    "              metrics={'task1_output': 'accuracy', 'task2_output': 'accuracy'})\n",
    "\n",
    "# 假设我们有任务1和任务2的数据\n",
    "x_train = np.random.randn(1000, 784)\n",
    "y_train_task1 = np.random.randint(10, size=(1000,))\n",
    "y_train_task2 = np.random.randint(2, size=(1000,))\n",
    "\n",
    "# 训练模型\n",
    "model.fit(x_train, {'task1_output': y_train_task1, 'task2_output': y_train_task2}, epochs=10, batch_size=32)\n",
    "```\n",
    "\n",
    "### 3. 迁移学习\n",
    "\n",
    "- **迁移学习（Transfer Learning）**：\n",
    "  - 迁移学习是将一个预训练模型在一个任务上的知识应用到另一个相关任务上的技术。\n",
    "  - **优点**：\n",
    "    - 减少训练时间。\n",
    "    - 在数据量有限的情况下，提高模型性能。\n",
    "\n",
    "#### 代码示例\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 加载预训练的VGG16模型，不包括顶部的全连接层\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# 冻结卷积层\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 添加新的全连接层\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# 构建迁移学习模型\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 假设我们有图像数据\n",
    "x_train = np.random.randn(100, 224, 224, 3)\n",
    "y_train = np.random.randint(10, size=(100,))\n",
    "\n",
    "# 训练模型\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
    "```\n",
    "\n",
    "### 4. 数据分割\n",
    "\n",
    "- **数据分割（Data Augmentation）**：\n",
    "  - 数据分割是通过对现有数据进行各种变换（如旋转、缩放、平移等）来生成更多训练数据的技术。\n",
    "  - **优点**：\n",
    "    - 增强模型的泛化能力。\n",
    "    - 减少过拟合。\n",
    "\n",
    "#### 代码示例\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 创建数据生成器\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "# 假设我们有图像数据\n",
    "x_train = np.random.randn(100, 224, 224, 3)\n",
    "\n",
    "# 拓展数据\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# 生成批量数据\n",
    "for x_batch in datagen.flow(x_train, batch_size=32):\n",
    "    # 处理生成的批量数据\n",
    "    break\n",
    "```\n",
    "\n",
    "### 5. 端到端深度学习\n",
    "\n",
    "- **端到端深度学习（End-to-end Deep Learning）**：\n",
    "  - 端到端深度学习是指构建一个模型，从原始输入数据到最终输出结果，全部通过一个模型来完成中间所有步骤。\n",
    "  - **优点**：\n",
    "    - 简化了模型的设计和实现。\n",
    "    - 避免了人为特征工程的过程。\n",
    "\n",
    "#### 代码示例\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 构建端到端模型\n",
    "input_layer = Input(shape=(None, 1))\n",
    "x = LSTM(128, return_sequences=True)(input_layer)\n",
    "x = LSTM(64)(x)\n",
    "output_layer = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 假设我们有时间序列数据\n",
    "x_train = np.random.randn(100, 10, 1)\n",
    "y_train = np.random.randn(100, 1)\n",
    "\n",
    "# 训练模型\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 深度学习 C4_W1\n",
    "\n",
    "### 1. 实现 CNN 的基础层（池化、卷积）\n",
    "\n",
    "- **池化层（Pooling Layer）**：\n",
    "  - 池化层用于减小输入的尺寸，并减少计算量和参数量。\n",
    "  - **常见的池化操作**：\n",
    "    - 最大池化（Max Pooling）\n",
    "    - 平均池化（Average Pooling）\n",
    "\n",
    "#### 代码示例\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
    "\n",
    "# 最大池化层\n",
    "max_pooling_layer = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))\n",
    "\n",
    "# 平均池化层\n",
    "average_pooling_layer = AveragePooling2D(pool_size=(2, 2), strides=(2, 2))\n",
    "```\n",
    "\n",
    "- **卷积层（Convolutional Layer）**：\n",
    "  - 卷积层用于提取输入数据的局部特征。\n",
    "  - **卷积操作**：\n",
    "    - 使用卷积核在输入数据上滑动，计算局部区域的加权和。\n",
    "\n",
    "#### 代码示例\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "# 卷积层\n",
    "conv_layer = Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')\n",
    "```\n",
    "\n",
    "### 2. CNN中使用的组件及用途（填充、步长、滤波器）\n",
    "\n",
    "- **填充（Padding）**：\n",
    "  - 填充是指在输入数据的边缘添加额外的像素，以控制卷积操作后的输出尺寸。\n",
    "  - **常见的填充方式**：\n",
    "    - 'valid'：不填充。\n",
    "    - 'same'：填充使得输出尺寸与输入尺寸相同。\n",
    "\n",
    "- **步长（Stride）**：\n",
    "  - 步长是指卷积核在输入数据上滑动的步幅。\n",
    "  - **步长设置**：\n",
    "    - 步长越大，输出尺寸越小。\n",
    "    - 步长越小，计算量越大。\n",
    "\n",
    "- **滤波器（Filter）**：\n",
    "  - 滤波器是卷积操作中的核心组件，用于提取\n",
    "\n",
    "特征。\n",
    "  - **滤波器数量**：\n",
    "    - 滤波器数量越多，提取的特征越多，但计算量和参数量也随之增加。\n",
    "\n",
    "#### 代码示例\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "# 卷积层示例\n",
    "conv_layer = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')\n",
    "```\n",
    "\n",
    "### 3. 构建CNN\n",
    "\n",
    "- **构建卷积神经网络（CNN）**：\n",
    "  - 使用卷积层、池化层和全连接层构建一个基本的卷积神经网络。\n",
    "\n",
    "#### 代码示例\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# 构建CNN模型\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 假设我们有图像数据\n",
    "x_train = np.random.randn(100, 64, 64, 3)\n",
    "y_train = np.random.randint(10, size=(100,))\n",
    "\n",
    "# 训练模型\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
    "```\n",
    "\n",
    "### 4. TF Keras Sequential创建情绪分类器\n",
    "\n",
    "- **创建情绪分类器**：\n",
    "  - 使用TensorFlow和Keras的Sequential API创建一个情绪分类器。\n",
    "\n",
    "#### 代码示例\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# 构建情绪分类器模型\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(7, activation='softmax')  # 7个情绪类别\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 假设我们有情绪图像数据\n",
    "x_train = np.random.randn(100, 48, 48, 1)\n",
    "y_train = np.random.randint(7, size=(100,))\n",
    "\n",
    "# 训练模型\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
    "```\n",
    "\n",
    "### 5. TensorFlow 中构建并训练 ConvNet\n",
    "\n",
    "- **构建并训练卷积神经网络（ConvNet）**：\n",
    "  - 使用TensorFlow构建一个卷积神经网络，并在数据集上进行训练。\n",
    "\n",
    "#### 代码示例\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# 构建ConvNet模型\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 假设我们有图像数据\n",
    "x_train = np.random.randn(100, 64, 64, 3)\n",
    "y_train = np.random.randint(10, size=(100,))\n",
    "\n",
    "# 训练模型\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
    "```\n",
    "\n",
    "### 6. ConvNet解决二分类和多分类问题\n",
    "\n",
    "- **ConvNet解决二分类问题**：\n",
    "  - 使用卷积神经网络解决二分类问题，例如猫狗分类。\n",
    "\n",
    "#### 代码示例\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# 构建二分类ConvNet模型\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # 二分类问题，使用sigmoid激活函数\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 假设我们有猫狗图像数据\n",
    "x_train = np.random.randn(100, 64, 64, 3)\n",
    "y_train = np.random.randint(2, size=(100,))\n",
    "\n",
    "# 训练模型\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
    "```\n",
    "\n",
    "- **ConvNet解决多分类问题**：\n",
    "  - 使用卷积神经网络解决多分类问题，例如手写数字识别。\n",
    "\n",
    "#### 代码示例\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# 构建多分类ConvNet模型\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')  # 多分类问题，使用softmax激活函数\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 假设我们有手写数字图像数据\n",
    "x_train = np.random.randn(100, 28, 28, 1)\n",
    "y_train = np.random.randint(10, size=(100,))\n",
    "\n",
    "# 训练模型\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
