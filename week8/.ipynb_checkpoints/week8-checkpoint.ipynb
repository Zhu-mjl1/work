{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de041a10",
   "metadata": {},
   "source": [
    "# week8\n",
    "*time: 2024-05-27 to 2024-06-01*\n",
    "# Deep Learning \n",
    "> 说明：`C1_W1`没有编码作业，所以本周没有`C1_W1`对应的文件夹\n",
    "## C1_W1_引言\n",
    "\n",
    "### 1.1 深度学习简介\n",
    "- **定义**：深度学习是一种通过多层神经网络来自动提取特征并进行学习的技术。\n",
    "- **结构**：由输入层、多个隐藏层和输出层组成。\n",
    "- **应用**：图像识别、语音识别、自然语言处理等。\n",
    "\n",
    "### 1.2 卷积神经网络 (CNN)\n",
    "- **定义**：专门用于处理图像数据的神经网络。\n",
    "- **主要组件**：\n",
    "  - **卷积层**：提取局部特征。公式：\n",
    "  $$ (I * K)(i,j) = \\sum_m \\sum_n I(i+m,j+n) \\cdot K(m,n) $$\n",
    "  - **池化层**：降维和去噪。常用方法有最大池化和平均池化。\n",
    "  - **全连接层**：将特征映射到输出空间。\n",
    "- **实例**：经典模型如LeNet、AlexNet、VGG、ResNet。\n",
    "\n",
    "#### 示例代码：构建一个简单的CNN\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "### 1.3 循环神经网络 (RNN)\n",
    "- **定义**：用于处理序列数据的神经网络。\n",
    "- **特点**：具有记忆能力，能够捕捉时间序列中的依赖关系。\n",
    "- **变体**：长短期记忆网络（LSTM）、门控循环单元（GRU）。\n",
    "- **公式**：隐状态更新$$ h_t = \\sigma(W_{hh} h_{t-1} + W_{xh} x_t) $$\n",
    "- **实例**：用于语言模型、语音识别。\n",
    "\n",
    "#### 示例代码：构建一个简单的LSTM\n",
    "```python\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=10000, output_dim=64),\n",
    "    tf.keras.layers.LSTM(128),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "### 1.4 深度学习评估\n",
    "- **指标**：准确率、精确率、召回率、F1分数。\n",
    "- **方法**：交叉验证、混淆矩阵。\n",
    "- **实例**：在分类任务中使用准确率来评估模型性能。\n",
    "\n",
    "#### 示例代码：评估模型性能\n",
    "```python\n",
    "# Assuming 'model' is a trained model and 'test_images', 'test_labels' are the test dataset\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "```\n",
    "\n",
    "## C1_W2_神经网络编程基础\n",
    "\n",
    "### 2.1 浅层神经网络相关模型构建\n",
    "- **结构**：输入层、一个隐藏层、输出层。\n",
    "- **前向传播**：计算输出值。公式$$ a^{[l]} = \\sigma(W^{[l]} a^{[l-1]} + b^{[l]}) $$\n",
    "- **实例**：手写数字识别中的两层神经网络。\n",
    "\n",
    "#### 示例代码：构建一个简单的浅层神经网络\n",
    "```python\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "### 2.2 学习算法的总体结构\n",
    "- **步骤**：\n",
    "  1. 初始化参数\n",
    "  2. 前向传播计算输出\n",
    "  3. 计算损失函数\n",
    "  4. 反向传播计算梯度\n",
    "  5. 更新参数\n",
    "- **公式**：梯度下降$$\\theta = \\theta - \\alpha \\frac{\\partial J}{\\partial \\theta} $$\n",
    "- **实例**：使用梯度下降法优化神经网络参数。\n",
    "\n",
    "#### 示例代码：使用梯度下降法\n",
    "```python\n",
    "# Manually implementing gradient descent for a simple linear model\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
    "\n",
    "# Model parameters\n",
    "W = np.random.randn()\n",
    "b = np.random.randn()\n",
    "\n",
    "# Learning rate\n",
    "lr = 0.01\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "    # Forward pass\n",
    "    Y_pred = W * X + b\n",
    "    loss = np.mean((Y - Y_pred) ** 2)\n",
    "    \n",
    "    # Backward pass\n",
    "    dW = -2 * np.mean(X * (Y - Y_pred))\n",
    "    db = -2 * np.mean(Y - Y_pred)\n",
    "    \n",
    "    # Update parameters\n",
    "    W -= lr * dW\n",
    "    b -= lr * db\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}: Loss {loss}')\n",
    "```\n",
    "\n",
    "### 2.3 矢量化进阶\n",
    "- **定义**：将标量运算转换为向量运算。\n",
    "- **优点**：提高计算效率。\n",
    "- **实例**：矩阵乘法代替for循环计算神经网络的前向传播和反向传播。\n",
    "\n",
    "#### 示例代码：矢量化实现\n",
    "```python\n",
    "# Using numpy for vectorized operations\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "X = np.random.rand(1000, 784)  # 1000 samples, 784 features\n",
    "W = np.random.rand(784, 10)    # weights for 10 classes\n",
    "b = np.random.rand(10)         # bias for 10 classes\n",
    "\n",
    "# Forward pass\n",
    "Z = np.dot(X, W) + b\n",
    "A = np.maximum(Z, 0)  # ReLU activation\n",
    "```\n",
    "\n",
    "### 2.4 广播 (Broadcast)\n",
    "- **定义**：在不同形状的张量之间进行运算的技术。\n",
    "- **优点**：提高代码简洁性和效率。\n",
    "- **实例**：两个不同形状的矩阵相加、乘法等。\n",
    "\n",
    "#### 广播规则\n",
    "1. 如果两个数组的轴长度相等，或者其中一个数组的轴长度为1，则认为它们在该轴上是兼容的。\n",
    "2. 如果数组的形状不同，在缺失和长度为1的维度上进行扩展，使它们形状一致。\n",
    "\n",
    "#### 示例代码：广播机制的应用\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# 示例 1: 标量和数组相加\n",
    "A = np.array([1, 2, 3])\n",
    "B = 2\n",
    "C = A + B\n",
    "print(\"标量和数组相加:\\n\", C)\n",
    "\n",
    "# 示例 2: 形状为 (3,1) 的数组和形状为 (1,4) 的数组相加\n",
    "A = np.array([[1], [2], [3]])\n",
    "B = np.array([[4, 5, 6, 7]])\n",
    "C = A + B\n",
    "print(\"\\n形状为 (3,1) 的数组和形状为 (1,4) 的数组相加:\\n\", C)\n",
    "\n",
    "# 示例 3: 两个形状不相同但兼容的数组相乘\n",
    "A = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "B = np.array([1, 2, 3])\n",
    "C = A * B\n",
    "print(\"\\n两个形状不相同但兼容的数组相乘:\\n\", C)\n",
    "\n",
    "# 示例 4: 更复杂的广播应用，形状为 (2,3,4) 的数组与形状为 (3,1) 的数组相加\n",
    "A = np.ones((2, 3, 4))\n",
    "B = np.arange(3).reshape((3, 1))\n",
    "C = A + B\n",
    "print(\"\\n形状为 (2,3,4) 的数组与形状为 (3,1) 的数组相加:\\n\", C)\n",
    "\n",
    "# 示例 5: 广播机制的其他应用，如形状为 (2,3,4) 的数组与形状为 (3,4) 的数组相加\n",
    "A = np.ones((2, 3, 4))\n",
    "B = np.arange(12).reshape((3, 4))\n",
    "C = A + B\n",
    "print(\"\\n形状为 (2,3,4) 的数组与形状为 (3,4) 的数组相加:\\n\", C)\n",
    "\n",
    "# 示例 6: 使用广播机制进行矩阵乘法\n",
    "A = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "B = np.array([[7, 8], [9, 10]])\n",
    "C = A @ B\n",
    "print(\"\\n使用广播机制进行矩阵乘法:\\n\", C)\n",
    "\n",
    "# 示例 7: 广播机制与更高维度数组的加法\n",
    "A = np.random.rand(5, 1, 4, 1)\n",
    "B = np.random.rand(1, 3, 1, 2)\n",
    "C = A + B\n",
    "print(\"\\n广播机制与更高维度数组的加法:\\n\", C)\n",
    "```\n",
    "\n",
    "### 解释\n",
    "\n",
    "1. **标量和数组相加**：直接将标量添加到数组的每个元素上。\n",
    "2. **形状为 (3,1) 的数组和形状为 (1,4) 的数组相加**：数组A沿第二维度扩展，数组B沿第一维度扩展。\n",
    "3. **两个形状不相同但兼容的数组相乘**：数组A和B的形状为 (2,3) 和 (3)，B沿第一维度扩展。\n",
    "4. **更复杂的广播应用**：数组A的形状为 (2,3,4)，数组B的形状为 (3,1)，B沿第一和第三维度扩展。\n",
    "5. **形状为 (2,3,4) 的数组与形状为 (3,4) 的数组相加**：数组B沿第一维度扩展。\n",
    "6. **矩阵乘法**：矩阵A形状为 (3,2)，矩阵B形状为 (2,2)，使用 @ 运算符进行矩阵乘法。\n",
    "7. **更高维度数组的加法**：数组A形状为 (5,1,4,1)，数组B形状为 (1,3,1,2)，分别沿对应的维度扩展。\n",
    "\n",
    "\n",
    "### 2.5 反向传播进阶\n",
    "- **定义**：计算损失函数对各层参数的梯度，并反向传播这些梯度以更新参数。\n",
    "- **高级技巧**：\n",
    "  - **梯度剪裁**：防止梯度爆炸。\n",
    "  - **动量**：加速收敛。公式$$ v = \\beta v + (1-\\beta) \\nabla J $$\n",
    "  - **Adam优化**：结合动量和自适应学习率。公式$$ m_t = \\beta_1 m_{t-1} + (1-\\beta_1)g_t $$\n",
    "- **实例**：在深度神经网络中使用Adam优化器进行训练。\n",
    "\n",
    "#### 示例代码：使用Adam优化器\n",
    "```python\n",
    "# Using Adam optimizer in a neural network\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
